{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81819a2d",
   "metadata": {},
   "source": [
    "# Scraping Top Repositories for Topics on GitHub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438cf7e7",
   "metadata": {},
   "source": [
    "### Web-scraping\n",
    "- Web scraping is an automatic method to obtain large amounts of data from websites. Most of this data is unstructured data in an HTML format which is then converted into structured data in a spreadsheet or a database so that it can be used in various applications. There are many different ways to perform web scraping to obtain data from websites."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ee0d8b",
   "metadata": {},
   "source": [
    "![](https://1000logos.net/wp-content/uploads/2021/05/GitHub-logo.png)\n",
    "\n",
    " GitHub is a website and cloud-based service that helps developers store and manage their code, as well as track and control changes to their code. It is commonly used to host open-source projects.\n",
    "\n",
    "- In this project I will be scraping the data of top repositories for topics on https://github.com/topics\n",
    "\n",
    "- I will be mainly using pandas,requests and Beautiful Soup libraries for this project "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151edbae",
   "metadata": {},
   "source": [
    "#### Project Outline\n",
    "\n",
    "- We're going to scrape https://github.com/topics\n",
    "- We'll get a list of topics. For each topic, we'll get topic title, topic page URL and topic description\n",
    "- For each topic, we'll get the top repositories in the topic from the topic page\n",
    "- For each repository, we'll grab the repo name, username, stars and repo URL\n",
    "- For each topic we'll create a CSV file in the following format:\n",
    "\n",
    "```\n",
    "Repo Name,Username,Stars,Repo URL\n",
    "three.js,mrdoob,69700,https://github.com/mrdoob/three.js\n",
    "libgdx,libgdx,18300,https://github.com/libgdx/libgdx\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eaaebde",
   "metadata": {},
   "source": [
    "## Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5310b63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952e7209",
   "metadata": {},
   "source": [
    "## 1.Scraping the list of topics from github\n",
    "-  use requests library to download the webpage \n",
    "-  use Beautiful Soup library to extract information from it.\n",
    "-  convert the information to Pandas dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d33d03",
   "metadata": {},
   "source": [
    "### Let's write the function to download the page "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c90007ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page():\n",
    "    topic_url='https://github.com/topics'\n",
    "    response=requests.get(topic_url)\n",
    "    if response.status_code!=200:\n",
    "        raise Exception('Failed to load page{}'.format(topic_url))\n",
    "    doc=BeautifulSoup(response.text,'html.parser')\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a25b9579",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=get_page()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b421df",
   "metadata": {},
   "source": [
    "### Let's create helper functions to parse information from the page"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb771bf",
   "metadata": {},
   "source": [
    "#### `scrape_topic_titles(docs)` function to scrape topic_titles\n",
    "![](https://i.imgur.com/ckGJOgC.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a47e3535",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scrape_topic_titles(doc):\n",
    "    selection_class = 'f3 lh-condensed mb-0 mt-1 Link--primary' \n",
    "    topic_title_tags = doc.find_all('p', {'class': selection_class})  #to get topics titles `p tag with the class as in the image was taken \n",
    "    topic_titles=[]\n",
    "\n",
    "    for titles in topic_title_tags:\n",
    "        topic_titles.append(titles.text)\n",
    "\n",
    "    return topic_titles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caa4bd8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3D', 'Ajax', 'Algorithm', 'Amp', 'Android']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles=scrape_topic_titles(doc)\n",
    "titles[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587c2b48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "60813252",
   "metadata": {},
   "source": [
    "#### `scrape_topic_desc(docs)` to scrape topic_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ab6af8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scrape_topic_desc(doc):\n",
    "    desc_selector = 'f5 color-fg-muted mb-0 mt-1'\n",
    "    topic_desc_tags = doc.find_all('p', {'class': desc_selector})\n",
    "    topic_descs=[]\n",
    "\n",
    "    for descs in topic_desc_tags:\n",
    "        topic_descs.append(descs.text.strip())\n",
    "    return topic_descs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "993d6a5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3D modeling is the process of virtually developing the surface and structure of a 3D object.',\n",
       " 'Ajax is a technique for creating interactive web applications.',\n",
       " 'Algorithms are self-contained sequences that carry out a variety of tasks.',\n",
       " 'Amp is a non-blocking concurrency library for PHP.',\n",
       " 'Android is an operating system built by Google designed for mobile devices.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc=scrape_topic_desc(doc)\n",
    "desc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c400bf1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "546a743d",
   "metadata": {},
   "source": [
    "#### `scrape_topic_url(doc)` function to scrape topic_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36264300",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scrape_topic_url(doc):\n",
    "    topic_link_tags=doc.find_all('a',{'class':'no-underline flex-1 d-flex flex-column'})\n",
    "    topic_urls=[]\n",
    "\n",
    "    for links in topic_link_tags:\n",
    "        topic_urls.append('https://github.com'+links['href'])\n",
    "\n",
    "\n",
    "    return topic_urls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ceaff30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://github.com/topics/3d',\n",
       " 'https://github.com/topics/ajax',\n",
       " 'https://github.com/topics/algorithm',\n",
       " 'https://github.com/topics/amphp',\n",
       " 'https://github.com/topics/android']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls=scrape_topic_url(doc)\n",
    "urls[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4645ac5d",
   "metadata": {},
   "source": [
    "#### Lets put all together in a single function `scrape_topics()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4388c6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_topics():\n",
    "    topic_url='https://github.com/topics'\n",
    "    response=requests.get(topic_url)\n",
    "    if response.status_code!=200:\n",
    "        raise Exception('Failed to load page{}'.format(topic_url))\n",
    "    topics_dict={'title':scrape_topic_titles(doc),'description':scrape_topic_desc(doc),'topic_url':scrape_topic_url(doc)} \n",
    "    return pd.DataFrame(topics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1de5012a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>topic_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3D</td>\n",
       "      <td>3D modeling is the process of virtually develo...</td>\n",
       "      <td>https://github.com/topics/3d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ajax</td>\n",
       "      <td>Ajax is a technique for creating interactive w...</td>\n",
       "      <td>https://github.com/topics/ajax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algorithm</td>\n",
       "      <td>Algorithms are self-contained sequences that c...</td>\n",
       "      <td>https://github.com/topics/algorithm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amp</td>\n",
       "      <td>Amp is a non-blocking concurrency library for ...</td>\n",
       "      <td>https://github.com/topics/amphp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Android</td>\n",
       "      <td>Android is an operating system built by Google...</td>\n",
       "      <td>https://github.com/topics/android</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       title                                        description  \\\n",
       "0         3D  3D modeling is the process of virtually develo...   \n",
       "1       Ajax  Ajax is a technique for creating interactive w...   \n",
       "2  Algorithm  Algorithms are self-contained sequences that c...   \n",
       "3        Amp  Amp is a non-blocking concurrency library for ...   \n",
       "4    Android  Android is an operating system built by Google...   \n",
       "\n",
       "                             topic_url  \n",
       "0         https://github.com/topics/3d  \n",
       "1       https://github.com/topics/ajax  \n",
       "2  https://github.com/topics/algorithm  \n",
       "3      https://github.com/topics/amphp  \n",
       "4    https://github.com/topics/android  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_df=scrape_topics()\n",
    "topics_df[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6506b3b",
   "metadata": {},
   "source": [
    "## Let's get top repositories from the topic page\n",
    "\n",
    "- now for each topic we will get information of top repositories\n",
    "- for that we will be defining some functions \n",
    "- at last we will store the data for each topic in a folder in csv file. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8729a0",
   "metadata": {},
   "source": [
    "#### `get_topic_page()` function returns the topic page "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e95e25fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_page(topic_url):\n",
    "    response=requests.get(topic_url)  #download page\n",
    "#     if response.status_code!=200:    #checking successful response\n",
    "#         raise Exception('Failed to load page')\n",
    "   \n",
    "        #parse using beautifulsoup\n",
    "    topic_doc=BeautifulSoup(response.text,'html.parser') \n",
    "    return topic_doc    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1882471f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exdoc=get_topic_page(urls[4])\n",
    "type(exdoc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b51ee2",
   "metadata": {},
   "source": [
    "#### `parse_star_count(star_str)` function returns the integer value of star count of a repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35b81a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parse_star_count(star_str) returns the number stars of a repo in integer\n",
    "def parse_star_count(star_str):  # like it converts 89k to 89000\n",
    "    star_str=star_str.strip()\n",
    "    if star_str[-1]=='k':\n",
    "        return int(float(star_str[:-1])*1000)\n",
    "    return int(star_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702e0271",
   "metadata": {},
   "source": [
    "#### `get_repo_info()` function  gives the repository info - username,repo_name,stars,repo_url\n",
    "\n",
    "- here the h3_tags contains 'username','repo_name'\n",
    "![](https://i.imgur.com/9ifxSn3.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa085c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_repos_dict={'username':[],'repo_name':[],'stars':[],'repo_url':[]} \n",
    "base_url='https://github.com/topics'\n",
    "\n",
    "def get_repo_info(h3_tag,star_tag):\n",
    "    a_tags=h3_tag.find_all('a')\n",
    "    username=a_tags[0].text.strip()\n",
    "    repo_name=a_tags[1].text.strip()\n",
    "    stars=parse_star_count(star_tag.text.strip())\n",
    "    repo_url=base_url+a_tags[1]['href']\n",
    "    return username,repo_name,stars,repo_url\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db72e9de",
   "metadata": {},
   "source": [
    "#### ` get_topic_repos(topic_doc)` function returns a pandas dataframe of the top repositories with its detais'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03d089c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_topic_repos(topic_doc):\n",
    "    #getting tags containing username,repo_name\n",
    "    h3_selection_class='f3 color-fg-muted text-normal lh-condensed' \n",
    "    h3_tags=topic_doc.find_all('h3',{'class':h3_selection_class})\n",
    "    \n",
    "    #getting tags containing stars\n",
    "    star_tags=topic_doc.find_all('span',{'class':'Counter js-social-count'})\n",
    "    for i in range(len(h3_tags)):\n",
    "        repo_info = get_repo_info(h3_tags[i],star_tags[i])\n",
    "        topic_repos_dict['username'].append(repo_info[0])\n",
    "        topic_repos_dict['repo_name'].append(repo_info[1])\n",
    "        topic_repos_dict['stars'].append(repo_info[2])\n",
    "        topic_repos_dict['repo_url'].append(repo_info[3])\n",
    "    return pd.DataFrame(topic_repos_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e51b9e2",
   "metadata": {},
   "source": [
    "#### `scrape_topic(topic_url,path)` function creates  csv file of from a topic's page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "418206af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_topic(topic_url,path):\n",
    "   \n",
    "    if os.path.exists(path+'.csv'):\n",
    "        print(\"The file {} already exists. Skipping...\".format(path))\n",
    "        return\n",
    "    topic_df=get_topic_repos(get_topic_page(topic_url))\n",
    "    topic_df.to_csv(path+'.csv',index=None)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290ea379",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "657939a9",
   "metadata": {},
   "source": [
    "## Now let's put all these together\n",
    "- we have a function to get list of topics \n",
    "- we have function to create csv file for the scraped repos from topics page .\n",
    "\n",
    "#### Let's create a function `scrape_topics_repos()` to put all of them together and save our CSV files for each topic and with their top repositories in a folder.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "efc4c277",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_topics_repos():\n",
    "    print('Scraping list of topics')\n",
    "    topics_df = scrape_topics()\n",
    "    \n",
    "    os.makedirs('datasets', exist_ok=True)\n",
    "    for index, row in topics_df.iterrows():\n",
    "        print('Scraping top repositories for \"{}\"'.format(row['title']))\n",
    "        scrape_topic(row['topic_url'], 'datasets/{}'.format(row['title']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b197ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping list of topics\n",
      "Scraping top repositories for \"3D\"\n",
      "Scraping top repositories for \"Ajax\"\n",
      "Scraping top repositories for \"Algorithm\"\n",
      "Scraping top repositories for \"Amp\"\n",
      "Scraping top repositories for \"Android\"\n",
      "Scraping top repositories for \"Angular\"\n",
      "Scraping top repositories for \"Ansible\"\n",
      "Scraping top repositories for \"API\"\n",
      "Scraping top repositories for \"Arduino\"\n",
      "Scraping top repositories for \"ASP.NET\"\n",
      "Scraping top repositories for \"Atom\"\n",
      "Scraping top repositories for \"Awesome Lists\"\n",
      "Scraping top repositories for \"Amazon Web Services\"\n",
      "Scraping top repositories for \"Azure\"\n",
      "Scraping top repositories for \"Babel\"\n",
      "Scraping top repositories for \"Bash\"\n",
      "Scraping top repositories for \"Bitcoin\"\n",
      "Scraping top repositories for \"Bootstrap\"\n",
      "Scraping top repositories for \"Bot\"\n",
      "Scraping top repositories for \"C\"\n",
      "Scraping top repositories for \"Chrome\"\n",
      "Scraping top repositories for \"Chrome extension\"\n",
      "Scraping top repositories for \"Command line interface\"\n",
      "Scraping top repositories for \"Clojure\"\n",
      "Scraping top repositories for \"Code quality\"\n",
      "Scraping top repositories for \"Code review\"\n",
      "Scraping top repositories for \"Compiler\"\n",
      "Scraping top repositories for \"Continuous integration\"\n",
      "Scraping top repositories for \"COVID-19\"\n",
      "Scraping top repositories for \"C++\"\n"
     ]
    }
   ],
   "source": [
    "scrape_topics_repos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcee064",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
